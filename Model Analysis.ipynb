{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run using Python 3.12.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import savetxt\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 160em;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set cell width\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# set cell output window height\n",
    "display(HTML(\"<style>div.output_scroll { height: 160em;} </style>\"))\n",
    "\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dan_oberdorf/Documents/Northwestern/MSDS 458 Artificial Intelligence and Deep Learning/Assignment'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MLP Models\n",
    "model_load_list = ['mlp_base_01','mlp_base_02','mlp_base_03','mlp_static_01','mlp_static_02','mlp_static_03','mlp_dynamic_01','mlp_dynamic_02','mlp_dynamic_03']\n",
    "\n",
    "model_wt_dict = {}\n",
    "\n",
    "for model in model_load_list:\n",
    "\n",
    "    file_name = f'./MLP_Models/{model}_final_wts.pkl'\n",
    "\n",
    "    model_name = f'{model}_final_wts'\n",
    "\n",
    "    with open(file_name,'rb') as f:\n",
    "        model_wt_dict[model_name] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mlp_base_01_final_wts', 'mlp_base_02_final_wts', 'mlp_base_03_final_wts', 'mlp_static_01_final_wts', 'mlp_static_02_final_wts', 'mlp_static_03_final_wts', 'mlp_dynamic_01_final_wts', 'mlp_dynamic_02_final_wts', 'mlp_dynamic_03_final_wts'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wt_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['final_W1', 'final_W2'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### confirm that the models are loaded with both weight sets\n",
    "model_wt_dict['mlp_base_01_final_wts'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tensor Flow Models\n",
    "tf_model_list = ['base_case_1','base_case_2','base_case_3','static_case_1','static_case_2','static_case_3','dyn_case_1','dyn_case_2','dyn_case_3']\n",
    "\n",
    "tf_model_dict = {}\n",
    "\n",
    "for model in tf_model_list:\n",
    "\n",
    "    file_name = f'./TF_Models/{model}.keras'\n",
    "    \n",
    "    tf_model_dict[model] = tf.keras.models.load_model(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Hidden_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Hidden_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,832</span> (112.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,832\u001b[0m (112.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,610</span> (37.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,610\u001b[0m (37.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,222</span> (75.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m19,222\u001b[0m (75.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_model_dict['base_case_1'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load and testing Test Split Functions\n",
    "def load_data(data_set):\n",
    "\n",
    "    # optionality to load two different data sets\n",
    "    if data_set.lower() == 'iris':\n",
    "        data = load_iris()\n",
    "        X=data.data\n",
    "        y=data.target\n",
    "    elif data_set.lower() == 'digits':\n",
    "        # data = load_digits()\n",
    "        training_data = pd.read_csv('./optical+recognition+of+handwritten+digits/optdigits.tra', header=None)\n",
    "        test_data = pd.read_csv('./optical+recognition+of+handwritten+digits/optdigits.tes', header=None)\n",
    "        xtr = training_data.loc[:,:63]\n",
    "        ytr = training_data.loc[:,64]\n",
    "        xte = test_data.loc[:,:63]\n",
    "        yte = test_data.loc[:,64]\n",
    "        full_x_df = pd.concat([pd.DataFrame(xtr),pd.DataFrame(xte)], axis = 0)\n",
    "        full_y_df = pd.concat([pd.DataFrame(ytr),pd.DataFrame(yte)], axis = 0)\n",
    "        full_x_df.columns = ['x'+str(x) for x in full_x_df.columns]\n",
    "        full_y_df.columns = ['Target']\n",
    "        X = np.array(full_x_df)\n",
    "        y = np.ndarray.flatten(np.array(full_y_df))\n",
    "\n",
    "    print(f'Dimensions of data {X.shape}')\n",
    "\n",
    "    # normalize data\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # map for three output nodes\n",
    "    y = pd.get_dummies(y).values\n",
    "    \n",
    "    return(X,y)\n",
    "\n",
    "########################################################\n",
    "\n",
    "def split_train_test(X, y, test_size, random_state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y, shuffle=True)\n",
    "    return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of data (5620, 64)\n"
     ]
    }
   ],
   "source": [
    "### Seed Storage for testing\n",
    "seed_split = 1\n",
    "\n",
    "### Load Data\n",
    "X, y = load_data('digits')\n",
    "\n",
    "### Split Data\n",
    "X_train, X_test, y_train, y_test = split_train_test(X, y, test_size = 0.2, random_state = seed_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_activations:\n",
    "\n",
    "    def __init__(self, w1, w2, x_df, y_df):\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        self.x_df = x_df\n",
    "        self.y_df = y_df\n",
    "        self.activ_df = pd.DataFrame()\n",
    "        self.action = self.activations()\n",
    "        \n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def activations(self):\n",
    "        for i, j in zip(self.x_df, self.y_df):\n",
    "            Z1 = i @ self.w1\n",
    "            A1 = self.sigmoid(Z1)\n",
    "            A1_flat = np.ndarray.flatten(np.round(A1,decimals=3))\n",
    "            Z2 = A1 @ self.w2\n",
    "            A2 = self.sigmoid(Z2)\n",
    "            A2_flat = np.ndarray.flatten(np.round(A2,decimals=3))\n",
    "            temp_df = pd.DataFrame({'digit_y':[np.argmax(j)],'A1':[A1_flat], 'A2':[A2_flat]})\n",
    "            self.activ_df = pd.concat([self.activ_df,temp_df], axis = 0, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_df_dict = {}\n",
    "\n",
    "for model in model_load_list:\n",
    "\n",
    "    model_name = f'{model}_final_wts'\n",
    "\n",
    "    act_temp = mlp_activations(model_wt_dict[model_name]['final_W1'],\n",
    "                                  model_wt_dict[model_name]['final_W2'],\n",
    "                                  X_test, y_test).activ_df\n",
    "    \n",
    "    activation_df_dict[model] = act_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit_y</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[0.159, 0.017, 0.005, 0.782, 0.998, 0.327, 0.5...</td>\n",
       "      <td>[0.005, 0.129, 0.001, 0.0, 0.003, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.001, 0.101, 0.09, 0.03, 0.996, 0.944, 0.967...</td>\n",
       "      <td>[0.0, 0.077, 0.003, 0.0, 0.013, 0.001, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.065, 0.301, 0.077, 0.777, 0.621, 0.661...</td>\n",
       "      <td>[0.002, 0.014, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>[0.001, 0.064, 0.018, 0.013, 0.999, 0.625, 0.9...</td>\n",
       "      <td>[0.066, 0.001, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.007, 0.478, 0.213, 0.175, 0.988, 0.959, 0.7...</td>\n",
       "      <td>[0.006, 0.002, 0.0, 0.0, 0.465, 0.0, 0.015, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.001, 0.448, 0.002, 0.021, 0.987, 0.603, 0.9...</td>\n",
       "      <td>[0.003, 0.02, 0.0, 0.0, 0.046, 0.0, 0.001, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>7</td>\n",
       "      <td>[0.001, 0.989, 0.12, 0.003, 0.985, 0.89, 0.939...</td>\n",
       "      <td>[0.0, 0.001, 0.001, 0.0, 0.037, 0.001, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.262, 0.139, 0.028, 0.999, 0.987, 0.981...</td>\n",
       "      <td>[0.003, 0.068, 0.0, 0.0, 0.003, 0.001, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.02, 0.152, 0.141, 0.048, 0.921, 0.817, 0.82...</td>\n",
       "      <td>[0.0, 0.005, 0.001, 0.0, 0.006, 0.006, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.471, 0.302, 0.147, 0.634, 0.123, 0.944...</td>\n",
       "      <td>[0.0, 0.004, 0.003, 0.0, 0.0, 0.012, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1124 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      digit_y                                                 A1                                                 A2\n",
       "0           6  [0.159, 0.017, 0.005, 0.782, 0.998, 0.327, 0.5...  [0.005, 0.129, 0.001, 0.0, 0.003, 0.0, 0.0, 0....\n",
       "1           2  [0.001, 0.101, 0.09, 0.03, 0.996, 0.944, 0.967...  [0.0, 0.077, 0.003, 0.0, 0.013, 0.001, 0.0, 0....\n",
       "2           3  [0.0, 0.065, 0.301, 0.077, 0.777, 0.621, 0.661...  [0.002, 0.014, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0,...\n",
       "3           9  [0.001, 0.064, 0.018, 0.013, 0.999, 0.625, 0.9...  [0.066, 0.001, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0,...\n",
       "4           5  [0.007, 0.478, 0.213, 0.175, 0.988, 0.959, 0.7...  [0.006, 0.002, 0.0, 0.0, 0.465, 0.0, 0.015, 0....\n",
       "...       ...                                                ...                                                ...\n",
       "1119        8  [0.001, 0.448, 0.002, 0.021, 0.987, 0.603, 0.9...  [0.003, 0.02, 0.0, 0.0, 0.046, 0.0, 0.001, 0.0...\n",
       "1120        7  [0.001, 0.989, 0.12, 0.003, 0.985, 0.89, 0.939...  [0.0, 0.001, 0.001, 0.0, 0.037, 0.001, 0.0, 0....\n",
       "1121        2  [0.0, 0.262, 0.139, 0.028, 0.999, 0.987, 0.981...  [0.003, 0.068, 0.0, 0.0, 0.003, 0.001, 0.0, 0....\n",
       "1122        8  [0.02, 0.152, 0.141, 0.048, 0.921, 0.817, 0.82...  [0.0, 0.005, 0.001, 0.0, 0.006, 0.006, 0.0, 0....\n",
       "1123        3  [0.0, 0.471, 0.302, 0.147, 0.634, 0.123, 0.944...  [0.0, 0.004, 0.003, 0.0, 0.0, 0.012, 0.0, 0.0,...\n",
       "\n",
       "[1124 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_df_dict['mlp_base_01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMAP Options\n",
    "viridis_r <br>\n",
    "Reds <br>\n",
    "magma <br>\n",
    "crest <br>\n",
    "mako <br> \n",
    "cubehelix <br>\n",
    "icefire <br>\n",
    "sns.diverging_palette(220, 20, as_cmap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class activation_heatmap:\n",
    "\n",
    "    def __init__(self, data_array, labels, title):\n",
    "        self.data_array = data_array\n",
    "        self.labels = labels\n",
    "        self.title = title\n",
    "        # self.action = self.graph()\n",
    "\n",
    "\n",
    "    def single_graph(self):\n",
    "\n",
    "        avg_act = np.mean(self.data_array.iloc[:,1], axis=0)\n",
    "        avg_act = avg_act.reshape(avg_act.shape[0],1)\n",
    "        avg_act = avg_act.T\n",
    "\n",
    "        plt.figure(figsize = (20,2.5))\n",
    "\n",
    "        sfig = sns.heatmap(avg_act, cmap=sns.color_palette(\"coolwarm\", as_cmap=True), cbar = False, square = False, yticklabels=False)\n",
    "        plt.title(self.title)\n",
    "        plt.xticks(fontsize = 14)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return sfig.get_figure()\n",
    "\n",
    "\n",
    "    def single_graph_tf(self):\n",
    "\n",
    "        avg_act = np.mean(self.data_array, axis=0)\n",
    "        avg_act = avg_act.reshape(avg_act.shape[0],1)\n",
    "        avg_act = avg_act.T\n",
    "\n",
    "        plt.figure(figsize = (20,2.5))\n",
    "\n",
    "        sfig = sns.heatmap(avg_act, cmap=sns.color_palette(\"coolwarm\", as_cmap=True), cbar = False, square = False, yticklabels=False)\n",
    "        plt.title(self.title)\n",
    "        plt.xticks(fontsize = 14)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return sfig.get_figure()\n",
    "\n",
    "\n",
    "    def multi_graph(self):\n",
    "        \n",
    "        fig, ax = plt.subplots(len(self.data_array), sharex = True, figsize = (10,10))\n",
    "        # plt.subplots_adjust(hspace = 0.01)\n",
    "\n",
    "        for i,j in enumerate(self.data_array):\n",
    "\n",
    "            j = j.reshape(j.shape[0],1).T\n",
    "            sns.heatmap(j, ax = ax[i], cmap=sns.color_palette(\"coolwarm\", as_cmap=True), cbar = False, square = False, yticklabels=[self.labels[i]])\n",
    "            \n",
    "        cbar_ax = fig.add_axes([0.92, 0.15, 0.03, 0.7])  # [left, bottom, width, height]\n",
    "        fig.colorbar(ax[0].collections[0], cax=cbar_ax)\n",
    "\n",
    "        plt.suptitle(self.title, fontsize = 18, y =0.92)\n",
    "\n",
    "        # plt.tight_layout(h_pad=0.5, rect=(0,0,0.9,1))\n",
    "        \n",
    "        return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Activation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__MLP Gameplan__\n",
    "1. For each model look at first 25 activations of the same number\n",
    "2. Get the average activations for each model for all nine digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dan_oberdorf/Documents/Northwestern/MSDS 458 Artificial Intelligence and Deep Learning/Assignment'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dan_oberdorf/Documents/Northwestern/MSDS 458 Artificial Intelligence and Deep Learning/Assignment/Model_Graphs'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('./Model_Graphs')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mlp_base_01 - 11% Complete.\n",
      "Finished mlp_base_02 - 22% Complete.\n",
      "Finished mlp_base_03 - 33% Complete.\n",
      "Finished mlp_static_01 - 44% Complete.\n",
      "Finished mlp_static_02 - 56% Complete.\n",
      "Finished mlp_static_03 - 67% Complete.\n",
      "Finished mlp_dynamic_01 - 78% Complete.\n",
      "Finished mlp_dynamic_02 - 89% Complete.\n",
      "Finished mlp_dynamic_03 - 100% Complete.\n"
     ]
    }
   ],
   "source": [
    "numeric_value = 6\n",
    "\n",
    "model_runner = 1\n",
    "keys_len = len(activation_df_dict.keys())\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "for key, model in activation_df_dict.items():\n",
    "\n",
    "    ## First 25 Hidden Layer\n",
    "    hid_wt = model.loc[:25,'A1'].to_numpy().T\n",
    "    labels = model.loc[:25,'digit_y'].values\n",
    "    title = f'{key} - Activations of first 25 Characters - Hidden Layer'\n",
    "    temp_fig = activation_heatmap(hid_wt, labels, title).multi_graph()\n",
    "    fig_label = f'{key}_f25_hid.png'\n",
    "    temp_fig.savefig(fig_label)\n",
    "    plt.close()\n",
    "\n",
    "    ## First 25 activations of a single numeric value Hidden Layer\n",
    "    hid_s_wt = model.loc[model.digit_y == numeric_value,['digit_y','A1']]\n",
    "    hid_s_act = hid_s_wt.A1.T.to_numpy()\n",
    "    hid_s_label = hid_s_wt.digit_y.values\n",
    "    title = f'{key} - Activations of first 25 Instances of \"{numeric_value}\" - Hidden Layer'\n",
    "    temp_fig = activation_heatmap(hid_s_act[:25], hid_s_label[:25], title).multi_graph()\n",
    "    fig_label = f'{key}_fs_hid.png'\n",
    "    temp_fig.savefig(fig_label)\n",
    "    plt.close()\n",
    "\n",
    "    ## Mean Activations of a single numeric value Hidden Layer\n",
    "    title = f'{key} - Average Activations for \"{numeric_value}\" - Hidden Layer'\n",
    "    temp_fig = activation_heatmap(hid_s_wt, hid_s_label, title).single_graph()\n",
    "    fig_label = f'{key}_fs_avg_hid.png'\n",
    "    temp_fig.savefig(fig_label)\n",
    "    plt.close()\n",
    "\n",
    "    ## First 25 Output Layer\n",
    "    out_wt = model.loc[:25,'A2'].to_numpy().T\n",
    "    title = f'{key} - Activations of first 25 Characters - Output Layer'\n",
    "    temp_fig = activation_heatmap(out_wt, labels, title).multi_graph()\n",
    "    fig_label = f'{key}_f25_out.png'\n",
    "    temp_fig.savefig(fig_label)\n",
    "    plt.close()\n",
    "\n",
    "    ## First 25 activations of a single numeric value Output Layer\n",
    "    out_s_wt = model.loc[model.digit_y == numeric_value,['digit_y','A2']]\n",
    "    out_s_act = out_s_wt.A2.T.to_numpy()\n",
    "    out_s_label = out_s_wt.digit_y.values\n",
    "    title = f'{key} - Activations of first 25 Instances of \"{numeric_value}\" - Output Layer'\n",
    "    temp_fig = activation_heatmap(out_s_act[:25], out_s_label[:25], title).multi_graph()\n",
    "    fig_label = f'{key}_fs_out.png'\n",
    "    temp_fig.savefig(fig_label)\n",
    "    plt.close()\n",
    "\n",
    "    ## Mean Activations of a single numeric value Output Layer\n",
    "    title = f'{key} - Average Activations for \"{numeric_value}\" - Output Layer'\n",
    "    temp_fig = activation_heatmap(out_s_wt, out_s_label, title).single_graph()\n",
    "    fig_label = f'{key}_fs_avg_out.png'\n",
    "    temp_fig.savefig(fig_label)\n",
    "    plt.close()\n",
    "\n",
    "    # mlp_graph_dictionary[key] = temp_dict\n",
    "    print(f'Finished {key} - {'{:.0%}'.format(model_runner / keys_len)} Complete.')\n",
    "    model_runner += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Out How to build the activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf_model_dict['base_case_1'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf_model_dict['base_case_1']\n",
    "\n",
    "\n",
    "\n",
    "_ = model.predict(X_test[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred = np.argmax(_,axis = 1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ans = np.argmax(y_test[:50], axis = 1)\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum(pred - ans) / 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.get_layer('Hidden_Layer').input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.get_layer('Hidden_Layer').output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.get_layer('Output_Layer').input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.get_layer('Output_Layer').output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "int_out = tf.keras.Model(model.get_layer('Hidden_Layer').input, model.get_layer('Hidden_Layer').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "int_out2 = tf.keras.Model(model.get_layer('Output_Layer').input, model.get_layer('Output_Layer').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "int_out2(int_out(X_test[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first_item = int_out(X_test[0].reshape((1,64)))\n",
    "first_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ap = np.array(first_item)\n",
    "ap = ap.flatten().reshape(128,1).T\n",
    "print(ap.shape)\n",
    "\n",
    "plt.figure(figsize = (20,1))\n",
    "\n",
    "sns.heatmap(ap, cmap=sns.color_palette(\"coolwarm\", as_cmap=True), cbar = False, square = False, yticklabels=False)\n",
    "plt.title('TensorFlow Activations', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.argmax(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.argmax(y_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second_item = int_out(X_test[1].reshape((1,64)))\n",
    "tp = np.array(second_item)\n",
    "tp = tp.flatten().reshape(128,1).T\n",
    "print(tp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20,1))\n",
    "\n",
    "sns.heatmap(tp, cmap=sns.color_palette(\"coolwarm\", as_cmap=True), cbar = False, square = False, yticklabels=False)\n",
    "plt.title('TensorFlow Activations', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "itemx = int_out(X_test[:10].reshape((10,64)))\n",
    "apa = np.array(itemx)\n",
    "apa = apa.flatten().reshape(128,10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TensorFlow Activation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorFlow_Activations:\n",
    "\n",
    "    def __init__(self, model, x_data, y_data, single_numeric = None, model_name = None):\n",
    "        self.model = model\n",
    "        self.x = x_data\n",
    "        self.y = y_data\n",
    "        self.model_nm = model_name\n",
    "        self.signle_num = single_numeric\n",
    "        self.hid_activ = np.array([])\n",
    "        self.out_activ = np.array([])\n",
    "        self.action = self.activations()\n",
    "        self.action = self.output()\n",
    "\n",
    "\n",
    "    def inter_activ_hidden(self, data_x):\n",
    "        '''\n",
    "        This function takes the x_data as input and return the activations.\n",
    "        '''\n",
    "        h_l = tf.keras.Model(self.model.get_layer('Hidden_Layer').input, \n",
    "                              self.model.get_layer('Hidden_Layer').output)\n",
    "        \n",
    "        return h_l(data_x)\n",
    "    \n",
    "\n",
    "    def inter_activ_output(self, data_hidden):\n",
    "        '''\n",
    "        This function takes the hidden layer outputs and returns activations for the output layer.\n",
    "        '''\n",
    "        o_l = tf.keras.Model(self.model.get_layer('Output_Layer').input, \n",
    "                              self.model.get_layer('Output_Layer').output)\n",
    "        \n",
    "        return o_l(data_hidden)\n",
    "\n",
    "\n",
    "    def activations(self):\n",
    "        '''\n",
    "        Generates a flattened multi-dimensional array of the activations.\n",
    "        '''\n",
    "        \n",
    "        ### Activations for the hidden layer\n",
    "        if len(self.x.shape) == 1:\n",
    "            x_shape = (1,self.x.shape[0])\n",
    "            x_in = self.x.reshape((1,self.x.shape[0]))\n",
    "        else:\n",
    "            x_shape = self.x.shape\n",
    "            x_in = self.x\n",
    "\n",
    "        item_h = self.inter_activ_hidden(x_in)\n",
    "\n",
    "        h_array = np.array(item_h)\n",
    "        new_shape = (x_shape[0],h_array.shape[1])\n",
    "        h_array = h_array.flatten().reshape(new_shape)\n",
    "\n",
    "        self.hid_activ = h_array\n",
    "\n",
    "        ### Activations for the output layer\n",
    "        item_o = self.inter_activ_output(item_h)\n",
    "\n",
    "        o_array = np.array(item_o)\n",
    "        new_shape = (x_shape[0],o_array.shape[1])\n",
    "        o_array = o_array.flatten().reshape(new_shape)\n",
    "\n",
    "        self.out_activ = o_array\n",
    "\n",
    "\n",
    "    def output(self):\n",
    "\n",
    "        labels = np.argmax(self.y, axis = 1)\n",
    "\n",
    "        if self.signle_num == None:\n",
    "\n",
    "            title1 = f'TensorFlow First 25 Activations for Hidden Layer -- {self.model_nm} Model'\n",
    "            title2 = f'TensorFlow First 25 Activations for Output Layer -- {self.model_nm} Model'\n",
    "        \n",
    "        else:\n",
    "\n",
    "            title1 = f'TensorFlow First 25 Instances of \"{self.signle_num}\" Activations for Hidden Layer -- {self.model_nm} Model'\n",
    "            title2 = f'TensorFlow First 25 Instances of \"{self.signle_num}\" Activations for Output Layer -- {self.model_nm} Model'\n",
    "\n",
    "        self.fig1 = activation_heatmap(self.hid_activ[:25], labels, title1).multi_graph()\n",
    "        self.fig2 = activation_heatmap(self.out_activ[:25], labels, title2).multi_graph()\n",
    "\n",
    "        return self.hid_activ, self.out_activ, self.fig1, self.fig2\n",
    "    \n",
    "\n",
    "    def avg_output(self):\n",
    "\n",
    "        if self.signle_num != None:\n",
    "            \n",
    "            title1 = f'TensorFlow Avg of 25 Instances of \"{self.signle_num}\" Activations for Hidden Layer -- {self.model_nm} Model'\n",
    "            title2 = f'TensorFlow Avg of 25 Instances of \"{self.signle_num}\" Activations for Output Layer -- {self.model_nm} Model'\n",
    "\n",
    "            self.fig1x = activation_heatmap(self.hid_activ[:25], labels, title1).single_graph_tf()\n",
    "            self.fig2x = activation_heatmap(self.out_activ[:25], labels, title2).single_graph_tf()\n",
    "\n",
    "            return self.fig1x, self.fig2x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlp_dynamic_03_final_wts'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jx/zq2lxw9x6xd9gzk5ybm8g2zm0000gn/T/ipykernel_24747/268389681.py:44: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(len(self.data_array), sharex = True, figsize = (10,10))\n"
     ]
    }
   ],
   "source": [
    "plt.ioff()\n",
    "tf_s_run = TensorFlow_Activations(model, xs[:25], ys[:25], single_numeric = numeric_value, model_name = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvals = np.argmax(y_test, axis = 1)\n",
    "single_index = np.where(yvals == numeric_value)\n",
    "xs, ys = X_test[single_index], y_test[single_index]\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "TF_ACTIV_DICT = {}\n",
    "\n",
    "for key, model in tf_model_dict.items():\n",
    "\n",
    "    ## First 25 Data Points Hidden and Output\n",
    "    tf_run = TensorFlow_Activations(model, X_test, y_test, model_name = key)\n",
    "    \n",
    "    ## Get Hidden Activations First 25\n",
    "    fig_label = f'TF_{key}_f25_hid.png'\n",
    "    tf_run.fig1.savefig(fig_label)\n",
    "\n",
    "    ## Get Output Activations First 25\n",
    "    fig_label = f'TF_{key}_f25_out.png'\n",
    "    tf_run.fig2.savefig(fig_label)\n",
    "\n",
    "    ## Put all activations into Dictionary\n",
    "    actuals = np.argmax(y_test, axis = 1)\n",
    "    TF_ACTIV_DICT[key] = {'hidden': tf_run.hid_activ.tolist(), 'output': tf_run.out_activ.tolist(), 'actuals': actuals.tolist()}\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    ## Single Value Activations\n",
    "    tf_s_run = TensorFlow_Activations(model, xs, ys, single_numeric = numeric_value, model_name = key)\n",
    "\n",
    "    ## Single Value Activations Hidden Layer\n",
    "    fig_label = f'TF_{key}_fs_hid.png'\n",
    "    tf_s_run.fig1.savefig(fig_label)\n",
    "\n",
    "    ## Single Value Activations Output Layer\n",
    "    fig_label = f'TF_{key}_fs_out.png'\n",
    "    tf_s_run.fig2.savefig(fig_label)\n",
    "\n",
    "    ## Single Value Avg\n",
    "    f1, f2 = tf_s_run.avg_output()\n",
    "\n",
    "    ## Single Value Avg Hidden Layer\n",
    "    fig_label = f'TF_{key}_fs_avg_hid.png'\n",
    "    f1.savefig(fig_label)\n",
    "\n",
    "    ## Single Value Avg Output Layer\n",
    "    fig_label = f'TF_{key}_fs_avg_out.png'\n",
    "    f2.savefig(fig_label)\n",
    "\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Dictionary\n",
    "\n",
    "with open(\"TF_Activations.json\",\"w\") as outx:\n",
    "    json.dump(TF_ACTIV_DICT, outx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06870344, 0.3465687 , 0.77779531, 0.29975724, 0.82588786,\n",
       "       0.06771056, 0.41504976, 0.0192846 , 0.57325661, 0.15579721,\n",
       "       0.48031461, 0.48373714, 0.15957054, 0.91085893, 0.91453385,\n",
       "       0.07133066, 0.83271706, 0.16786216, 0.0805342 , 0.37374043,\n",
       "       0.19244498, 0.31338242, 0.5707202 , 0.22518955, 0.14075969,\n",
       "       0.42177257, 0.97827131, 0.73420346, 0.11030316, 0.00258984,\n",
       "       0.75918281, 0.72320396, 0.81358463, 0.11875726, 0.34139639,\n",
       "       0.97037977, 0.9718473 , 0.80764645, 0.59878546, 0.80945075,\n",
       "       0.67920411, 0.31916258, 0.76765215, 0.01013992, 0.43757966,\n",
       "       0.3524504 , 0.93210328, 0.56690371, 0.20304789, 0.90595025,\n",
       "       0.15391961, 0.62112832, 0.798715  , 0.01399727, 0.2024022 ,\n",
       "       0.0037299 , 0.99553156, 0.95401496, 0.56033748, 0.14967313,\n",
       "       0.42206326, 0.8059966 , 0.72539306, 0.34916013, 0.61628711,\n",
       "       0.15840209, 0.66200179, 0.46102321, 0.06548133, 0.08399698,\n",
       "       0.83268613, 0.12262796, 0.95963484, 0.94464272, 0.86261189,\n",
       "       0.45999813, 0.94093841, 0.9312728 , 0.98332781, 0.89753759,\n",
       "       0.29954392, 0.19140887, 0.2616379 , 0.5070352 , 0.17156363,\n",
       "       0.79355484, 0.20766808, 0.68909848, 0.18501194, 0.51023245,\n",
       "       0.7283234 , 0.25363806, 0.96188319, 0.87257046, 0.61442095,\n",
       "       0.98065495, 0.66758955, 0.93427509, 0.90779895, 0.05267205,\n",
       "       0.37889263, 0.00827973, 0.57003093, 0.5102939 , 0.49459028,\n",
       "       0.83177698, 0.95037204, 0.45302343, 0.0481071 , 0.75306845,\n",
       "       0.03120484, 0.17371002, 0.3265942 , 0.2273199 , 0.38011089,\n",
       "       0.22735621, 0.94330519, 0.50317031, 0.40356806, 0.7528643 ,\n",
       "       0.92131799, 0.07470838, 0.31777498, 0.81231964, 0.40415204,\n",
       "       0.01036907, 0.98861945, 0.31856957])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(TF_ACTIV_DICT['base_case_1']['hidden'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
